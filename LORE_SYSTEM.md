# ğŸ“š Lore Context Caching System

## âœ… **COMPLETE - Ready to Use!**

A flexible lore management system using Gemini's context caching API. Add your 18 pages of lore and the AI will have deep world knowledge at 1/10th the cost!

---

## ğŸ“ **Folder Structure**

```
lore/
â”œâ”€â”€ cache_config.json      â† Configuration
â”œâ”€â”€ text/                  â† Your lore documents
â”‚   â”œâ”€â”€ 00_README.md      â† Instructions
â”‚   â”œâ”€â”€ EXAMPLE_world_overview.md
â”‚   â”œâ”€â”€ 01_your_lore.md   â† Add your files here!
â”‚   â”œâ”€â”€ 02_timeline.txt
â”‚   â””â”€â”€ ...
â””â”€â”€ images/                â† Reference images
    â”œâ”€â”€ facility_map.png
    â”œâ”€â”€ character_ref.jpg
    â””â”€â”€ ...
```

---

## ğŸš€ **How to Use**

### **Step 1: Enable the System**

Edit `lore/cache_config.json`:
```json
{
  "enabled": true,  â† Set to true
  "ttl_hours": 2,
  "auto_refresh": true
}
```

### **Step 2: Add Your Lore**

Place your 18 pages in `lore/text/`:
```bash
lore/text/01_world_overview.md
lore/text/02_horizon_industries.md
lore/text/03_characters.md
lore/text/04_timeline.txt
...
```

**Supported formats:**
- `.md` - Markdown (recommended)
- `.txt` - Plain text
- Any UTF-8 text file

### **Step 3: Add Reference Images (Optional)**

Place images in `lore/images/`:
```bash
lore/images/facility_map.png
lore/images/character_jason.jpg
lore/images/logo_horizon.png
```

**Supported formats:**
- `.png`, `.jpg`, `.jpeg`, `.webp`

### **Step 4: Start Bot**

```bash
python bot.py
```

The bot will automatically:
1. âœ… Load all lore files
2. âœ… Create Gemini cache
3. âœ… Include cache in every AI call
4. âœ… Auto-refresh when files change

---

## ğŸ’¬ **Discord Commands**

### **`/lore_status`**
View current cache status:
```
ğŸ“š Lore Cache Status
âœ… Active
ğŸ“„ Files: 4 text, 2 images
ğŸ”¢ Tokens: 12,450
â° Expires in: 1:23:45
ğŸ’° Storage cost: $0.0125/hour
ğŸ†” Cache ID: cachedContents...
```

### **`/lore_refresh`**
Force immediate cache refresh:
```
âœ… Lore Cache Refreshed
[Shows updated status]
```

---

## âš™ï¸ **Configuration Options**

Edit `lore/cache_config.json`:

```json
{
  "enabled": true,              // Enable/disable caching
  "ttl_hours": 2,               // Cache lifetime (1-24 hours)
  "auto_refresh": true,         // Auto-refresh on file changes
  "check_interval_seconds": 60, // How often to check for changes
  "file_order": [               // Optional: explicit load order
    "text/01_world_overview.md",
    "text/02_timeline.md",
    "images/facility_map.png"
  ]
}
```

### **File Order**

If `file_order` is specified:
- âœ… Files load in exact order listed
- âœ… Useful for logical sequencing

If `file_order` is empty/missing:
- âœ… Auto-loads all `.md`/`.txt` from `text/` (alphabetically)
- âœ… Then loads all images from `images/` (alphabetically)

---

## ğŸ”„ **Hot Reloading**

The system automatically detects file changes:

```
1. You edit: lore/text/05_new_chapter.md
2. Save file [Ctrl+S]
3. Bot detects change (within 60 seconds)
4. Cache refreshes automatically
5. Next turn uses updated lore!
```

**No bot restart needed!** ğŸ‰

---

## ğŸ’° **Cost Breakdown**

### **LAZY LOADING: $0 When Idle!**

The cache is **NOT created when bot starts**. It's only created when someone actually plays.

```
Bot running, no players â†’ No cache â†’ $0 ğŸ’š
           â†“
Player clicks Play â†’ Cache created â†’ Start charging â°
           â†“
Player finishes (2 hours) â†’ Cache expires â†’ Back to $0 ğŸ’š
           â†“
Next day, new player â†’ Cache recreated â†’ Charged again â°
```

### **Cost During Active Gameplay**

Assume:
- 18 pages â‰ˆ 12,000 tokens
- 100 AI calls per 2-hour session
- Cache expires after session

#### **Without Caching:**
```
100 calls Ã— 12k tokens = 1.2M tokens
Cost: 1.2M Ã— $0.075/1M = $0.090 per session
```

#### **With Caching (Lazy):**
```
Cache creation: 12k tokens Ã— $0.075/1M = $0.0009 (once per session)
Cache storage: 12k tokens Ã— $1.00/1M Ã— 2 hours = $0.024 (only while playing)
100 calls: 12k cached tokens Ã— $0.01/1M Ã— 100 = $0.012 (during session)
Total: $0.037 per session
```

**Savings: 59% cheaper per session!**

**Idle cost: $0** (cache doesn't exist when no one is playing) ğŸ‰

---

## ğŸ¯ **How It Works Technically**

### **1. Cache Creation**
```python
# Load all lore files
parts = []
for file in lore_files:
    if text_file:
        parts.append({"text": file_content})
    elif image_file:
        parts.append({"inlineData": {...}})

# Create cache via Gemini API
cache = gemini.cachedContents.create(
    model="gemini-2.0-flash-exp",
    contents=[{"role": "user", "parts": parts}],
    ttl="7200s"  # 2 hours
)
```

### **2. Using Cache**
```python
# Every AI call includes cache reference
response = gemini.generateContent(
    model="gemini-2.0-flash-exp",
    cachedContent=cache.name,  # â† Reference cached lore
    contents="Player choice..."
)
```

### **3. File Monitoring**
```python
# Check file modification times every 60s
if files_modified():
    refresh_cache()
```

---

## ğŸ“Š **Features**

| Feature | Status |
|---------|--------|
| Text files (`.md`, `.txt`) | âœ… |
| Image files (`.png`, `.jpg`, `.webp`) | âœ… |
| Hot reloading | âœ… |
| Auto-refresh on changes | âœ… |
| Manual refresh command | âœ… |
| Status monitoring | âœ… |
| Custom file ordering | âœ… |
| Cost optimization | âœ… |
| Multi-provider (Gemini only) | âš ï¸ |

**Note:** Context caching is Gemini-only. When using OpenAI provider, lore is not cached (but still works, just costs more).

---

## ğŸ® **Use Cases**

### **World Consistency**
```
Lore: "Horizon Industries was founded in 1987"
Player: "When was this place built?"
AI: "According to records, Horizon Industries established 
     this facility in 1987..."
```

### **Character Knowledge**
```
Lore: "Jason Fleece is 34 years old, journalist"
Player: "How old am I?"
AI: "You're 34, though the stress of recent events 
     has aged you beyond your years."
```

### **Location Details**
```
Lore Image: [facility_map.png showing Building C-7]
Player: "Where am I?"
AI: "You're standing outside Building C-7, the main 
     research wing according to the facility map."
```

---

## ğŸ› **Troubleshooting**

### **Cache not creating?**
- Check `lore/cache_config.json` has `"enabled": true`
- Ensure lore files exist in `lore/text/`
- Check logs for API errors
- Verify `GEMINI_API_KEY` is set

### **Files not detected?**
- Make sure files are in `lore/text/` or `lore/images/`
- Check file extensions (`.md`, `.txt`, `.png`, etc.)
- Wait up to 60 seconds for auto-detection
- Use `/lore_refresh` for immediate update

### **Cache expired?**
- Default TTL is 2 hours
- Increase `ttl_hours` in config
- Max TTL is 24 hours per Gemini API

### **High costs?**
- Cache storage: $1/M tokens/hour
- 12k tokens = $0.012/hour
- If too high, reduce lore or use shorter TTL

---

## ğŸš€ **Next Steps**

1. âœ… **Add your 18 pages** to `lore/text/`
2. âœ… **Add reference images** to `lore/images/` (optional)
3. âœ… **Enable caching** in `cache_config.json`
4. âœ… **Start bot** and check `/lore_status`
5. âœ… **Test it** - AI should reference your lore!

**Your lore is now part of the AI's knowledge base!** ğŸ“šâœ¨

